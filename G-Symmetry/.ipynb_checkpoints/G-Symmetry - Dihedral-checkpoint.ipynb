{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d4be473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "from qiskit import *\n",
    "\n",
    "# Importing standard Qiskit libraries\n",
    "from qiskit.tools.jupyter import *\n",
    "from qiskit.visualization import *\n",
    "from qiskit.providers.aer import QasmSimulator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "from qiskit.utils import QuantumInstance\n",
    "\n",
    "from qiskit.opflow import I, X, Y, Z\n",
    "from qiskit.opflow import StateFn\n",
    "from qiskit.opflow import Gradient\n",
    "from qiskit.opflow import CircuitSampler\n",
    "from qiskit.opflow.primitive_ops import MatrixOp\n",
    "\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit.circuit import QuantumCircuit\n",
    "from qiskit.circuit import ParameterVector\n",
    "from qiskit.circuit.library import RealAmplitudes\n",
    "\n",
    "from qiskit.algorithms.optimizers import SPSA\n",
    "from qiskit.algorithms.optimizers import COBYLA\n",
    "from qiskit.algorithms.optimizers import GradientDescent\n",
    "from qiskit.algorithms.optimizers import ADAM\n",
    "\n",
    "from qiskit.providers.aer.noise import NoiseModel\n",
    "\n",
    "from qiskit.quantum_info import Statevector\n",
    "from qiskit.ignis.mitigation.measurement import CompleteMeasFitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93b3626c",
   "metadata": {},
   "outputs": [],
   "source": [
    "provider = IBMQ.load_account()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a63af03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_numb(low_in,high_in):\n",
    "    '''\n",
    "    Returns a random number between low_in and high_in, including both end points.\n",
    "    '''\n",
    "    return np.random.uniform(low=low_in, high=np.nextafter(high_in, np.inf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d366d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Define variables for the number of layers and qubits of the prover. Define global variables used in the optimization.\n",
    "'''\n",
    "numLayer = 4\n",
    "numQubit = 2\n",
    "global iterations\n",
    "global noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bb2e1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createProver(numQubit, numLayer):\n",
    "    '''\n",
    "    Creates a parameterized unitary on numQubit qubits. Applies numLayer layers of the HEA with 2 Qiskit.parameters \n",
    "    per qubit per layer, specifying rotations about the x- and y-axes. After each layer, applies a neighbouring qubit\n",
    "    CNOT layer. Returns a QuantumCircuit object containing the parameterized prover. \n",
    "    '''\n",
    "    numparam = numQubit*numLayer*2\n",
    "    prover = QuantumCircuit(numQubit)\n",
    "    param_vector = ParameterVector(\"params\", numparam)\n",
    "    \n",
    "    for j in range(numLayer):\n",
    "        for i in range(numQubit):\n",
    "            prover.rx(param_vector[j*2*numQubit + i], i)\n",
    "            prover.ry(param_vector[j*2*numQubit + i + numQubit], i)\n",
    "\n",
    "        for i in range(numQubit-1):\n",
    "            prover.cx(i, i+1)\n",
    "            \n",
    "    return prover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dd799b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 872.774x367.889 with 1 Axes>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Defines parameters that specify the purification of state to be tested. Create a QuantumCircuit object that\n",
    "creates the purification on (size) number of qubits.\n",
    "'''\n",
    "unitary_param_1 = np.array([])\n",
    "size = 4\n",
    "layers = 2\n",
    "\n",
    "for i in range(0, 2*size*layers):\n",
    "    unitary_param_1 = np.append(unitary_param_1, np.array([rand_numb(0,2*np.pi)]))\n",
    "\n",
    "state = QuantumCircuit(size)\n",
    "for j in range(layers):\n",
    "    for i in range(size):\n",
    "        state.rx(unitary_param_1[j*size*2 + i], i)\n",
    "        state.ry(unitary_param_1[j*2*size + i + size], i)\n",
    "\n",
    "    for i in range(size-1):\n",
    "        state.cx(i, i+1)\n",
    "\n",
    "state.draw('mpl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ecea772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createEqSuperposDihedral():\n",
    "    '''\n",
    "    Defines a quantum circuit to create the uniform superposition of basis elements required.\n",
    "    '''\n",
    "    temp = QuantumCircuit(3)\n",
    "    temp.ry(2*np.arctan(1/np.sqrt(2)), 0)\n",
    "    temp.x(0)\n",
    "    temp.ch(0, 1)\n",
    "    temp.x(0)\n",
    "    temp.h(2)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa3022ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createQuantumCircuit(state, numQubit, numLayer):\n",
    "    '''\n",
    "    Creates quantum circuit for the problem. \n",
    "    Refer to Section 3.B from https://arxiv.org/pdf/2105.12758\n",
    "    The ciruit contains 7 qubits each labelled as (C, S, S')\n",
    "    '''\n",
    "    circ = QuantumCircuit(7)\n",
    "    \n",
    "    superPosCircuit = createEqSuperposDihedral()\n",
    "    circ.append(superPosCircuit, [0, 1, 2])\n",
    "\n",
    "    circ.append(state, [3, 4, 5, 6])\n",
    "    \n",
    "    prover = createProver(numQubit, numLayer)\n",
    "    circ.append(prover, [5, 6])\n",
    "    \n",
    "    circ.ccx(2, 4, 3)\n",
    "    circ.ccx(2, 6, 5)\n",
    "    \n",
    "    circ.cswap(1, 3, 4)\n",
    "    circ.cswap(1, 5, 6)\n",
    "    \n",
    "    circ.ccx(0, 3, 4)\n",
    "    circ.ccx(0, 5, 6)\n",
    "    \n",
    "    circ.append(superPosCircuit.inverse(), [0, 1, 2])\n",
    "    \n",
    "    return circ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "562911ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'createQuantumCircuit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-dde630c5711a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mCreates\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mquantum\u001b[0m \u001b[0mcircuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m '''\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mqCirc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreateQuantumCircuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumQubit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mqCirc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mpl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'createQuantumCircuit' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Creates the quantum circuit\n",
    "'''\n",
    "qCirc = createQuantumCircuit(state, numQubit, numLayer)\n",
    "qCirc.draw('mpl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a4dbb91",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qCirc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-6b588638aba1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mquantum\u001b[0m \u001b[0mcircuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m '''\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqCirc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'qCirc' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "List of parameters of the quantum circuit.\n",
    "'''\n",
    "print(qCirc.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bdaa747",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Pick a backend to use. We use the statevector_simulator for noiseless simulation.\n",
    "'''\n",
    "noiseless_backend = Aer.get_backend('statevector_simulator')\n",
    "noiseless_q_instance = QuantumInstance(noiseless_backend)\n",
    "noiseless_sampler = CircuitSampler(noiseless_q_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4adcac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Pick a backend to use. We use the qasm_simulator for noisy simulation.\n",
    "'''\n",
    "provider = IBMQ.get_provider(hub=\"ibm-q-research\", group=\"louisiana-st-uni-1\", project=\"main\")\n",
    "noisy_backend = Aer.get_backend(\"qasm_simulator\")\n",
    "device = provider.get_backend(\"ibmq_jakarta\")\n",
    "coupling_map = device.configuration().coupling_map\n",
    "noise_model = NoiseModel.from_backend(device.properties())\n",
    "noisy_q_instance = QuantumInstance(backend=noisy_backend, \n",
    "                           shots=8192, \n",
    "                           noise_model=noise_model, \n",
    "                           coupling_map=coupling_map,\n",
    "                           measurement_error_mitigation_cls=CompleteMeasFitter,\n",
    "                           cals_matrix_refresh_period=30)\n",
    "noisy_sampler = CircuitSampler(noisy_q_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfc62040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def costf(params):\n",
    "    '''\n",
    "    Assigns the params input to the parameters of the ansatz, and calculates the expectation value.\n",
    "    '''\n",
    "    expectation = StateFn(hamiltonian, is_measurement=True).compose(StateFn(qCirc))\n",
    "    value_dict = dict(zip(qCirc.parameters, params))\n",
    "    \n",
    "    if noisy:\n",
    "        result = noisy_sampler.convert(expectation, params=value_dict).eval()  \n",
    "    else:\n",
    "        result = noiseless_sampler.convert(expectation, params=value_dict).eval()  \n",
    "    \n",
    "    return -1*np.real(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e113236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(params):\n",
    "    '''\n",
    "    Assigns the params input to the parameters of the ansatz, and calculates the gradient value.\n",
    "    '''\n",
    "    expectation = StateFn(hamiltonian, is_measurement=True).compose(StateFn(qCirc))\n",
    "    value_dict = dict(zip(qCirc.parameters, params))\n",
    "    gradient = Gradient().convert(expectation)\n",
    "    \n",
    "    if noisy:\n",
    "        result = noisy_sampler.convert(gradient, params=value_dict).eval()  \n",
    "    else:\n",
    "        result = noiseless_sampler.convert(gradient, params=value_dict).eval()  \n",
    "    \n",
    "    return -1*np.real(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90f3d2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autospsa_callback(nfev, x, fx, stepsize, accepted = False):\n",
    "    '''\n",
    "    Callback function called automatically during optimization. Appends loss value, current iteration and \n",
    "    prints every iteration with a completion percentage.\n",
    "    '''\n",
    "    if (noisy == True):\n",
    "        noisy_loss.append(-1*fx)\n",
    "    else:\n",
    "        noiseless_loss.append(-1*fx)\n",
    "    print(\"Loss Value : \", -1*fx, str(nfev/3)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe6c2a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Average value of this hamiltonian is the probability of measuring 0 on the first three qubit.\n",
    "MatrixOp(np.array([[1, 0], [0, 0])) is the projector on the 0 subspace. Qiskit orders qubits in reverse.\n",
    "'''\n",
    "hamiltonian = I^I^I^I^MatrixOp(np.array([[1, 0], [0, 0]]))^MatrixOp(np.array([[1, 0], [0, 0]]))^MatrixOp(np.array([[1, 0], [0, 0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32bd6992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.46680178 6.20802905 1.32279227 1.26837821 3.05003389 2.91351481\n",
      " 3.38989789 5.58618413 3.63741698 2.63505645 0.04325302 0.05223526\n",
      " 3.29680683 2.44598817 5.76685489 3.41259299]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'qCirc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-e72d93e465f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparamProver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initial Cost : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcostf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparamProver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-6728ffc7a380>\u001b[0m in \u001b[0;36mcostf\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mAssigns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mparams\u001b[0m \u001b[0minput\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mansatz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcalculates\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mexpectation\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     '''\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mexpectation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStateFn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhamiltonian\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_measurement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStateFn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqCirc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mvalue_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqCirc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'qCirc' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Initialize prover parameters to random angles\n",
    "'''\n",
    "numParam = 2*numQubit*numLayer\n",
    "noisy = False\n",
    "paramProver = []\n",
    "for i in range(0, numParam):\n",
    "    paramProver = np.append(paramProver, np.array([rand_numb(0,2*np.pi)]))\n",
    "print(paramProver)\n",
    "\n",
    "print(\"Initial Cost : \", -1*costf(paramProver))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3410a81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "True value calculated using the SDP.\n",
    "'''\n",
    "true_value = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "eef647cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Cost :  0.5537164718571056\n",
      "Loss Value :  0.551864779989593 1.0%\n",
      "Loss Value :  0.7350045373505899 2.0%\n",
      "Loss Value :  0.7451564705680201 3.0%\n",
      "Loss Value :  0.762569506482133 4.0%\n",
      "Loss Value :  0.8037845881513711 5.0%\n",
      "Loss Value :  0.8196746220709296 6.0%\n",
      "Loss Value :  0.8186711637295423 7.0%\n",
      "Loss Value :  0.8294320011009831 8.0%\n",
      "Loss Value :  0.8330166323640514 9.0%\n",
      "Loss Value :  0.8345656144203899 10.0%\n",
      "Loss Value :  0.884705429771876 11.0%\n",
      "Loss Value :  0.9042216025257062 12.0%\n",
      "Loss Value :  0.904798742986558 13.0%\n",
      "Loss Value :  0.9115561167984805 14.0%\n",
      "Loss Value :  0.9213076497277501 15.0%\n",
      "Loss Value :  0.9242370378576121 16.0%\n",
      "Loss Value :  0.9241464832711838 17.0%\n",
      "Loss Value :  0.9778036088822711 18.0%\n",
      "Loss Value :  0.9823283421208989 19.0%\n",
      "Loss Value :  0.985053892179103 20.0%\n",
      "Loss Value :  0.9854581752333693 21.0%\n",
      "Loss Value :  0.9910541370855541 22.0%\n",
      "Loss Value :  0.9911169269203539 23.0%\n",
      "Loss Value :  0.9911238816526211 24.0%\n",
      "Loss Value :  0.9914105449233622 25.0%\n",
      "Loss Value :  0.9914103649803172 26.0%\n",
      "Loss Value :  0.9858120269181916 27.0%\n",
      "Loss Value :  0.9933093725937461 28.0%\n",
      "Loss Value :  0.9950949214862349 29.0%\n",
      "Loss Value :  0.996409307406277 30.0%\n",
      "Loss Value :  0.9963197012176211 31.0%\n",
      "Loss Value :  0.9969230474890103 32.0%\n",
      "Loss Value :  0.9974843162800251 33.0%\n",
      "Loss Value :  0.9985365238677284 34.0%\n",
      "Loss Value :  0.9993689481705654 35.0%\n",
      "Loss Value :  0.9993842297579764 36.0%\n",
      "Loss Value :  0.9995988281543928 37.0%\n",
      "Loss Value :  0.9995980229615898 38.0%\n",
      "Loss Value :  0.9995417095978196 39.0%\n",
      "Loss Value :  0.9996366114041823 40.0%\n",
      "Loss Value :  0.9997112358531746 41.0%\n",
      "Loss Value :  0.9997129593803332 42.0%\n",
      "Loss Value :  0.9997218430372397 43.0%\n",
      "Loss Value :  0.9996185150977068 44.0%\n",
      "Loss Value :  0.9997800011862542 45.0%\n",
      "Loss Value :  0.9998762616619215 46.0%\n",
      "Loss Value :  0.9999152435728405 47.0%\n",
      "Loss Value :  0.9999148024970108 48.0%\n",
      "Loss Value :  0.9999547257261423 49.0%\n",
      "Loss Value :  0.9999177007212638 50.0%\n",
      "Loss Value :  0.9999216517636398 51.0%\n",
      "Loss Value :  0.999862808798605 52.0%\n",
      "Loss Value :  0.9998495613586824 53.0%\n",
      "Loss Value :  0.9998205606452089 54.0%\n",
      "Loss Value :  0.9999160615224922 55.0%\n",
      "Loss Value :  0.9998920909121392 56.0%\n",
      "Loss Value :  0.9999132623309702 57.0%\n",
      "Loss Value :  0.9999200616918833 58.0%\n",
      "Loss Value :  0.9999039800038613 59.0%\n",
      "Loss Value :  0.9999191379003936 60.0%\n",
      "Loss Value :  0.9999242537731781 61.0%\n",
      "Loss Value :  0.9999273147662318 62.0%\n",
      "Loss Value :  0.9999433295246535 63.0%\n",
      "Loss Value :  0.9999176256368282 64.0%\n",
      "Loss Value :  0.9999599474365695 65.0%\n",
      "Loss Value :  0.999967552784954 66.0%\n",
      "Loss Value :  0.999967658228784 67.0%\n",
      "Loss Value :  0.9999400564559504 68.0%\n",
      "Loss Value :  0.9999366682436868 69.0%\n",
      "Loss Value :  0.9999490595029772 70.0%\n",
      "Loss Value :  0.9999391137816012 71.0%\n",
      "Loss Value :  0.9999398185594429 72.0%\n",
      "Loss Value :  0.9999071696891293 73.0%\n",
      "Loss Value :  0.9999124398424958 74.0%\n",
      "Loss Value :  0.9998652574390094 75.0%\n",
      "Loss Value :  0.9998675183624626 76.0%\n",
      "Loss Value :  0.999617406403721 77.0%\n",
      "Loss Value :  0.9995954903991883 78.0%\n",
      "Loss Value :  0.9996179477407696 79.0%\n",
      "Loss Value :  0.99964698174737 80.0%\n",
      "Loss Value :  0.9996497681080709 81.0%\n",
      "Loss Value :  0.9996681242101825 82.0%\n",
      "Loss Value :  0.9996970995857986 83.0%\n",
      "Loss Value :  0.9997222989420117 84.0%\n",
      "Loss Value :  0.9997550761361811 85.0%\n",
      "Loss Value :  0.9997529226244096 86.0%\n",
      "Loss Value :  0.9997521576798254 87.0%\n",
      "Loss Value :  0.9997492943344762 88.0%\n",
      "Loss Value :  0.9997722472230869 89.0%\n",
      "Loss Value :  0.9997519181459755 90.0%\n",
      "Loss Value :  0.9997271095721494 91.0%\n",
      "Loss Value :  0.9996396366625854 92.0%\n",
      "Loss Value :  0.9996305847580701 93.0%\n",
      "Loss Value :  0.9999317137637902 94.0%\n",
      "Loss Value :  0.9999127514817981 95.0%\n",
      "Loss Value :  0.9998985272556857 96.0%\n",
      "Loss Value :  0.9998486332065606 97.0%\n",
      "Loss Value :  0.9998579181327993 98.0%\n",
      "Loss Value :  0.9999130355957987 99.0%\n",
      "Loss Value :  0.9999106398180094 100.0%\n",
      "Loss Value :  0.9999106912483199 101.0%\n",
      "Loss Value :  0.9999265609956901 102.0%\n",
      "Loss Value :  0.9999595320749921 103.0%\n",
      "Loss Value :  0.9999513670998623 104.0%\n",
      "Loss Value :  0.9999474763871326 105.0%\n",
      "Loss Value :  0.9999475289725405 106.0%\n",
      "Loss Value :  0.9999521859613163 107.0%\n",
      "Loss Value :  0.9999592400672752 108.0%\n",
      "Loss Value :  0.9996576623955603 109.0%\n",
      "Loss Value :  0.9996691743736721 110.0%\n",
      "Loss Value :  0.9996538426455646 111.0%\n",
      "Loss Value :  0.9997206702508898 112.0%\n",
      "Loss Value :  0.9997407709213746 113.0%\n",
      "Loss Value :  0.9997539013680407 114.0%\n",
      "Loss Value :  0.9998585567475556 115.0%\n",
      "Loss Value :  0.9998572538909791 116.0%\n",
      "Loss Value :  0.999869961068009 117.0%\n",
      "Loss Value :  0.9998558940612243 118.0%\n",
      "Loss Value :  0.9998613698184766 119.0%\n",
      "Loss Value :  0.99988740262169 120.0%\n",
      "Loss Value :  0.9998922141094431 121.0%\n",
      "Loss Value :  0.9999051503311502 122.0%\n",
      "Loss Value :  0.9998989016535687 123.0%\n",
      "Loss Value :  0.9998995750520564 124.0%\n",
      "Loss Value :  0.999903854149887 125.0%\n",
      "Loss Value :  0.9999052383762167 126.0%\n",
      "Loss Value :  0.9999733846632638 127.0%\n",
      "Loss Value :  0.9999723193688693 128.0%\n",
      "Loss Value :  0.9999662829828662 129.0%\n",
      "Loss Value :  0.9999897105977068 130.0%\n",
      "Loss Value :  0.9999880534161573 131.0%\n",
      "Loss Value :  0.9999848361496678 132.0%\n",
      "Loss Value :  0.9999536900532523 133.0%\n",
      "Loss Value :  0.9999823834652402 134.0%\n",
      "Loss Value :  0.9999785958250241 135.0%\n",
      "Loss Value :  0.9999824225351888 136.0%\n",
      "Loss Value :  0.9999833281521395 137.0%\n",
      "Loss Value :  0.9999834993360339 138.0%\n",
      "Loss Value :  0.9999447479873812 139.0%\n",
      "Loss Value :  0.9999090846686887 140.0%\n",
      "Loss Value :  0.999909966194974 141.0%\n",
      "Loss Value :  0.9998938510205683 142.0%\n",
      "Loss Value :  0.9998939590360327 143.0%\n",
      "Loss Value :  0.9998984762737255 144.0%\n",
      "Loss Value :  0.9998993430287276 145.0%\n",
      "Loss Value :  0.9999123612158303 146.0%\n",
      "Loss Value :  0.9999184811428329 147.0%\n",
      "Loss Value :  0.9999177402061403 148.0%\n",
      "Loss Value :  0.9999351573758681 149.0%\n",
      "Loss Value :  0.999937398381392 150.0%\n",
      "Loss Value :  0.9999462790731216 151.0%\n",
      "Loss Value :  0.9999446336163871 152.0%\n",
      "Loss Value :  0.9999184975654338 153.0%\n",
      "Loss Value :  0.9999189629996891 154.0%\n",
      "Loss Value :  0.9999321950778141 155.0%\n",
      "Loss Value :  0.9999301647270431 156.0%\n",
      "Loss Value :  0.9999346550387809 157.0%\n",
      "Loss Value :  0.99993448986223 158.0%\n",
      "Loss Value :  0.9999305928582133 159.0%\n",
      "Loss Value :  0.9999160469854209 160.0%\n",
      "Loss Value :  0.9999102580223038 161.0%\n",
      "Loss Value :  0.999882024934743 162.0%\n",
      "Loss Value :  0.9999224857911685 163.0%\n",
      "Loss Value :  0.999921216545711 164.0%\n",
      "Loss Value :  0.9999068152286925 165.0%\n",
      "Loss Value :  0.9999454086145343 166.0%\n",
      "Loss Value :  0.9999408930780089 167.0%\n",
      "Loss Value :  0.999939390897513 168.0%\n",
      "Loss Value :  0.999936861226209 169.0%\n",
      "Loss Value :  0.9999583315833939 170.0%\n",
      "Loss Value :  0.9999660114046973 171.0%\n",
      "Loss Value :  0.9999617180531206 172.0%\n",
      "Loss Value :  0.9999273539351754 173.0%\n",
      "Loss Value :  0.9999288770565906 174.0%\n",
      "Loss Value :  0.9999309894340654 175.0%\n",
      "Loss Value :  0.9999189015672952 176.0%\n",
      "Loss Value :  0.9999207725818805 177.0%\n",
      "Loss Value :  0.9999229185497372 178.0%\n",
      "Loss Value :  0.9999106292949143 179.0%\n",
      "Loss Value :  0.9999100562541439 180.0%\n",
      "Loss Value :  0.9999248350473704 181.0%\n",
      "Loss Value :  0.9999370484695312 182.0%\n",
      "Loss Value :  0.9999437663361722 183.0%\n",
      "Loss Value :  0.9999480857517571 184.0%\n",
      "Loss Value :  0.9998949771271961 185.0%\n",
      "Loss Value :  0.9999104590255147 186.0%\n",
      "Loss Value :  0.9999278470595776 187.0%\n",
      "Loss Value :  0.9999674595433268 188.0%\n",
      "Loss Value :  0.9999719282697925 189.0%\n",
      "Loss Value :  0.9999669982238134 190.0%\n",
      "Loss Value :  0.9999690202473079 191.0%\n",
      "Loss Value :  0.9999686040611481 192.0%\n",
      "Loss Value :  0.9999713410795383 193.0%\n",
      "Loss Value :  0.9999691129703822 194.0%\n",
      "Loss Value :  0.9999683030893446 195.0%\n",
      "Loss Value :  0.9999781242673473 196.0%\n",
      "Loss Value :  0.9999780768050271 197.0%\n",
      "Loss Value :  0.9999776071148008 198.0%\n",
      "Loss Value :  0.9999335908043763 199.0%\n",
      "Loss Value :  0.9999372300840748 200.0%\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Perform the noiseless optimization using the SPSA algorithm for 200 iterations.\n",
    "'''\n",
    "noisy = False\n",
    "noiseless_loss = []\n",
    "noiselessParam = np.copy(paramProver)\n",
    "print(\"Initial Cost : \", -1*costf(noiselessParam))\n",
    "autospsa = SPSA(maxiter=200, learning_rate=None, perturbation=None, callback=autospsa_callback)\n",
    "x_opt, fx_opt, nfevs = autospsa.optimize(numParam, costf, initial_point=noiselessParam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e27eabb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Cost :  0.431601968609507\n",
      "Loss Value :  0.4670876210882151 1.0%\n",
      "Loss Value :  0.5976317388427297 2.0%\n",
      "Loss Value :  0.5033412041140436 3.0%\n",
      "Loss Value :  0.6349859919802916 4.0%\n",
      "Loss Value :  0.6183210648988143 5.0%\n",
      "Loss Value :  0.5487658302267402 6.0%\n",
      "Loss Value :  0.5680124593953728 7.0%\n",
      "Loss Value :  0.5614303225250563 8.0%\n",
      "Loss Value :  0.5523303698059235 9.0%\n",
      "Loss Value :  0.5504979648319688 10.0%\n",
      "Loss Value :  0.6601383897964627 11.0%\n",
      "Loss Value :  0.615825455969025 12.0%\n",
      "Loss Value :  0.678609539510642 13.0%\n",
      "Loss Value :  0.510946460183711 14.0%\n",
      "Loss Value :  0.5262500011110645 15.0%\n",
      "Loss Value :  0.5175940955083278 16.0%\n",
      "Loss Value :  0.5034829167111242 17.0%\n",
      "Loss Value :  0.5813873745484468 18.0%\n",
      "Loss Value :  0.6604168711229161 19.0%\n",
      "Loss Value :  0.5996615119722323 20.0%\n",
      "Loss Value :  0.6080738391750172 21.0%\n",
      "Loss Value :  0.531273252068604 22.0%\n",
      "Loss Value :  0.5321895359829296 23.0%\n",
      "Loss Value :  0.5578704601257306 24.0%\n",
      "Loss Value :  0.5910679533402707 25.0%\n",
      "Loss Value :  0.6039557781720053 26.0%\n",
      "Loss Value :  0.5884508403971568 27.0%\n",
      "Loss Value :  0.6824528176835548 28.0%\n",
      "Loss Value :  0.5774971166194426 29.0%\n",
      "Loss Value :  0.5993136614376376 30.0%\n",
      "Loss Value :  0.675686833882711 31.0%\n",
      "Loss Value :  0.5709345742196819 32.0%\n",
      "Loss Value :  0.6525900863012787 33.0%\n",
      "Loss Value :  0.6548100532440756 34.0%\n",
      "Loss Value :  0.7480056168648745 35.0%\n",
      "Loss Value :  0.7183265969054927 36.0%\n",
      "Loss Value :  0.6510364843604242 37.0%\n",
      "Loss Value :  0.5395480770095733 38.0%\n",
      "Loss Value :  0.636663449675316 39.0%\n",
      "Loss Value :  0.6203345496555757 40.0%\n",
      "Loss Value :  0.6324171700634564 41.0%\n",
      "Loss Value :  0.7252652915117999 42.0%\n",
      "Loss Value :  0.6377915735065682 43.0%\n",
      "Loss Value :  0.6491527998225352 44.0%\n",
      "Loss Value :  0.6703088366059646 45.0%\n",
      "Loss Value :  0.6746487787792942 46.0%\n",
      "Loss Value :  0.6098559914067792 47.0%\n",
      "Loss Value :  0.5814454104016947 48.0%\n",
      "Loss Value :  0.7930675097089999 49.0%\n",
      "Loss Value :  0.7084220590012437 50.0%\n",
      "Loss Value :  0.6967997154147776 51.0%\n",
      "Loss Value :  0.5609712181613303 52.0%\n",
      "Loss Value :  0.7836486995560135 53.0%\n",
      "Loss Value :  0.7779182051667499 54.0%\n",
      "Loss Value :  0.6003710679844576 55.0%\n",
      "Loss Value :  0.5969544310110274 56.0%\n",
      "Loss Value :  0.6980354354836655 57.0%\n",
      "Loss Value :  0.6740511615536643 58.0%\n",
      "Loss Value :  0.6218032680357178 59.0%\n",
      "Loss Value :  0.7361872703988618 60.0%\n",
      "Loss Value :  0.7426428960129879 61.0%\n",
      "Loss Value :  0.6430410904307793 62.0%\n",
      "Loss Value :  0.680433444750986 63.0%\n",
      "Loss Value :  0.7122131808867921 64.0%\n",
      "Loss Value :  0.6849949648324831 65.0%\n",
      "Loss Value :  0.7504584392549379 66.0%\n",
      "Loss Value :  0.6580091004468187 67.0%\n",
      "Loss Value :  0.6529627029823044 68.0%\n",
      "Loss Value :  0.5616597276220763 69.0%\n",
      "Loss Value :  0.7378126014170171 70.0%\n",
      "Loss Value :  0.7281883987373179 71.0%\n",
      "Loss Value :  0.6268251651326021 72.0%\n",
      "Loss Value :  0.5629541580627704 73.0%\n",
      "Loss Value :  0.5845156793764821 74.0%\n",
      "Loss Value :  0.648040421366939 75.0%\n",
      "Loss Value :  0.6627076523259483 76.0%\n",
      "Loss Value :  0.6493240455262906 77.0%\n",
      "Loss Value :  0.6387933540823102 78.0%\n",
      "Loss Value :  0.7194919606598661 79.0%\n",
      "Loss Value :  0.6883133864638841 80.0%\n",
      "Loss Value :  0.5558404062801741 81.0%\n",
      "Loss Value :  0.5485056520979869 82.0%\n",
      "Loss Value :  0.5579950866829728 83.0%\n",
      "Loss Value :  0.7319665164031848 84.0%\n",
      "Loss Value :  0.7109977284658604 85.0%\n",
      "Loss Value :  0.6961713101363917 86.0%\n",
      "Loss Value :  0.5416871843514646 87.0%\n",
      "Loss Value :  0.6459384035061122 88.0%\n",
      "Loss Value :  0.6280632527143934 89.0%\n",
      "Loss Value :  0.6315965556110723 90.0%\n",
      "Loss Value :  0.6589568137792582 91.0%\n",
      "Loss Value :  0.6452732602089477 92.0%\n",
      "Loss Value :  0.7271402712073979 93.0%\n",
      "Loss Value :  0.7514629537691865 94.0%\n",
      "Loss Value :  0.626395475592614 95.0%\n",
      "Loss Value :  0.6262083754581554 96.0%\n",
      "Loss Value :  0.642969463440241 97.0%\n",
      "Loss Value :  0.6315075556194308 98.0%\n",
      "Loss Value :  0.6662797193104303 99.0%\n",
      "Loss Value :  0.5735880464425273 100.0%\n",
      "Loss Value :  0.7589472255790484 101.0%\n",
      "Loss Value :  0.7647979828793177 102.0%\n",
      "Loss Value :  0.7521607442097137 103.0%\n",
      "Loss Value :  0.6681243613906253 104.0%\n",
      "Loss Value :  0.6581052757461568 105.0%\n",
      "Loss Value :  0.6276113617460033 106.0%\n",
      "Loss Value :  0.5672099947733055 107.0%\n",
      "Loss Value :  0.6527644906077513 108.0%\n",
      "Loss Value :  0.6440681923753181 109.0%\n",
      "Loss Value :  0.6316054475104885 110.0%\n",
      "Loss Value :  0.7298253154456527 111.0%\n",
      "Loss Value :  0.7460023374131302 112.0%\n",
      "Loss Value :  0.6676298732832384 113.0%\n",
      "Loss Value :  0.7722130354422131 114.0%\n",
      "Loss Value :  0.6789291699659705 115.0%\n",
      "Loss Value :  0.6626995160397927 116.0%\n",
      "Loss Value :  0.667365622978747 117.0%\n",
      "Loss Value :  0.6520635832144392 118.0%\n",
      "Loss Value :  0.752094761271225 119.0%\n",
      "Loss Value :  0.5824921631670817 120.0%\n",
      "Loss Value :  0.6129762137709082 121.0%\n",
      "Loss Value :  0.612926739249764 122.0%\n",
      "Loss Value :  0.6821815613353347 123.0%\n",
      "Loss Value :  0.7684014792397463 124.0%\n",
      "Loss Value :  0.6666664851226057 125.0%\n",
      "Loss Value :  0.7074106895132816 126.0%\n",
      "Loss Value :  0.5930040376285793 127.0%\n",
      "Loss Value :  0.7697251821699527 128.0%\n",
      "Loss Value :  0.6874766337883088 129.0%\n",
      "Loss Value :  0.5958731192364962 130.0%\n",
      "Loss Value :  0.6579452268146921 131.0%\n",
      "Loss Value :  0.6533048329643973 132.0%\n",
      "Loss Value :  0.6647441402389292 133.0%\n",
      "Loss Value :  0.7811030021141775 134.0%\n",
      "Loss Value :  0.5976393832751309 135.0%\n",
      "Loss Value :  0.7860265695701351 136.0%\n",
      "Loss Value :  0.6948431133896219 137.0%\n",
      "Loss Value :  0.5892421767948343 138.0%\n",
      "Loss Value :  0.6751780451868921 139.0%\n",
      "Loss Value :  0.6631948499718159 140.0%\n",
      "Loss Value :  0.5512049300277498 141.0%\n",
      "Loss Value :  0.6257974449572881 142.0%\n",
      "Loss Value :  0.5503989856770285 143.0%\n",
      "Loss Value :  0.61814554382352 144.0%\n",
      "Loss Value :  0.6305428922732318 145.0%\n",
      "Loss Value :  0.5494981038542261 146.0%\n",
      "Loss Value :  0.6245061217877801 147.0%\n",
      "Loss Value :  0.7329958319926695 148.0%\n",
      "Loss Value :  0.6394642814453133 149.0%\n",
      "Loss Value :  0.7290508619210413 150.0%\n",
      "Loss Value :  0.6271852630880723 151.0%\n",
      "Loss Value :  0.6492064429834837 152.0%\n",
      "Loss Value :  0.6691531996707455 153.0%\n",
      "Loss Value :  0.7524477733054432 154.0%\n",
      "Loss Value :  0.613053151092147 155.0%\n",
      "Loss Value :  0.6950916779492374 156.0%\n",
      "Loss Value :  0.7517272526360759 157.0%\n",
      "Loss Value :  0.7671963096979642 158.0%\n",
      "Loss Value :  0.7574047058770256 159.0%\n",
      "Loss Value :  0.6675537922131264 160.0%\n",
      "Loss Value :  0.5965489810417894 161.0%\n",
      "Loss Value :  0.6814074441899516 162.0%\n",
      "Loss Value :  0.6461132652143822 163.0%\n",
      "Loss Value :  0.7406864119976622 164.0%\n",
      "Loss Value :  0.5794061602882382 165.0%\n",
      "Loss Value :  0.7947068878631692 166.0%\n",
      "Loss Value :  0.5918427931325805 167.0%\n",
      "Loss Value :  0.7326601214915449 168.0%\n",
      "Loss Value :  0.7635544829360339 169.0%\n",
      "Loss Value :  0.7643193804778707 170.0%\n",
      "Loss Value :  0.5963035056554765 171.0%\n",
      "Loss Value :  0.7668781178290439 172.0%\n",
      "Loss Value :  0.7328731902685813 173.0%\n",
      "Loss Value :  0.6851507501740841 174.0%\n",
      "Loss Value :  0.5838787218945748 175.0%\n",
      "Loss Value :  0.6729117439676504 176.0%\n",
      "Loss Value :  0.7811957847295479 177.0%\n",
      "Loss Value :  0.7750150643607283 178.0%\n",
      "Loss Value :  0.7548459468722871 179.0%\n",
      "Loss Value :  0.7390721984141019 180.0%\n",
      "Loss Value :  0.748621769945379 181.0%\n",
      "Loss Value :  0.6717241306000444 182.0%\n",
      "Loss Value :  0.7396958484447372 183.0%\n",
      "Loss Value :  0.7626761308441481 184.0%\n",
      "Loss Value :  0.6489759235866426 185.0%\n",
      "Loss Value :  0.6405274806707644 186.0%\n",
      "Loss Value :  0.639542802058289 187.0%\n",
      "Loss Value :  0.7441427214310563 188.0%\n",
      "Loss Value :  0.7569308395816745 189.0%\n",
      "Loss Value :  0.7462333290975935 190.0%\n",
      "Loss Value :  0.661900582420582 191.0%\n",
      "Loss Value :  0.5956002913810854 192.0%\n",
      "Loss Value :  0.7589936306063151 193.0%\n",
      "Loss Value :  0.757310187544726 194.0%\n",
      "Loss Value :  0.7410067702172429 195.0%\n",
      "Loss Value :  0.6602022946310071 196.0%\n",
      "Loss Value :  0.7236620919281174 197.0%\n",
      "Loss Value :  0.7383718275510335 198.0%\n",
      "Loss Value :  0.6443142681787394 199.0%\n",
      "Loss Value :  0.6563872488744034 200.0%\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Perform the noisy optimization using the SPSA algorithm for 200 iterations.\n",
    "'''\n",
    "noisy = True\n",
    "noisy_loss = []\n",
    "noisyParam = np.copy(paramProver)\n",
    "-1*costf(noisyParam)\n",
    "print(\"Initial Cost : \", -1*costf(noisyParam))\n",
    "autospsa = SPSA(maxiter=200, learning_rate=None, perturbation=None, callback=autospsa_callback)\n",
    "x_opt, fx_opt, nfevs = autospsa.optimize(numParam, costf, initial_point=noisyParam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb4ce08e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_opt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-ec95ae82c693>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m '''\n\u001b[1;32m      4\u001b[0m \u001b[0mnoisy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnoiseResilientValue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcostf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_opt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoiseResilientValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_opt' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Evaluate the noiseless cost function using the parameters learned from the noisy optimization. \n",
    "'''\n",
    "noisy = False\n",
    "noiseResilientValue = -1*costf(x_opt)\n",
    "print(noiseResilientValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e04813f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Value :  1.0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'noiseless_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-5f692288f5a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m '''\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"True Value : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Noiseless : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoiseless_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Noisy : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoisy_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Noise Resilient Value : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoiseResilientValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'noiseless_loss' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Print all final values after training.\n",
    "'''\n",
    "print(\"True Value : \", true_value)\n",
    "print(\"Noiseless : \", noiseless_loss[-1])\n",
    "print(\"Noisy : \", noisy_loss[-1])\n",
    "print(\"Noise Resilient Value : \", noiseResilientValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ac1c8d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeToFile():\n",
    "    '''\n",
    "    Write the training data to a text file to be used to plot the data. The format is as follows:\n",
    "        True Value\n",
    "        Noise Resilient Value\n",
    "        Size of noiseless data list\n",
    "        [\n",
    "        Noiseless data with one entry per line\n",
    "        ]\n",
    "        Size of noisy data list\n",
    "        [\n",
    "        Noisy data with one entry per line\n",
    "        ]\n",
    "    '''\n",
    "    file = open(\"Dihedral_GS.txt\", \"w+\")\n",
    "    file.write(str(true_value)+\"\\n\")\n",
    "    file.write(str(noiseResilientValue)+\"\\n\")\n",
    "\n",
    "    file.write(str(len(noiseless_loss))+\"\\n\")\n",
    "    L = [str(i)+\"\\n\" for i in noiseless_loss]\n",
    "    file.writelines(L)\n",
    "    \n",
    "    file.write(str(len(noisy_loss))+\"\\n\")\n",
    "    L = [str(i)+\"\\n\" for i in noisy_loss[0:len(noisy_loss)-1]]\n",
    "    file.writelines(L)\n",
    "    \n",
    "    file.write(str(noisy_loss[-1]))\n",
    "    \n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3314ae8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "writeToFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27afd3ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
